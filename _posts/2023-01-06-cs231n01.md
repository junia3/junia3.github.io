---
title: cs231n 내용 요약 (1) - What is deep learning?
layout: post
description: Lecture summary
use_math: true
post-image: https://user-images.githubusercontent.com/79881119/210934049-762c2540-c097-4107-89ba-32bd2b8bc9f3.png
category: deep learning
tags:
- AI
- Deep learning
- cs231n
---

# Overview

인공지능이란 무엇일까? 원래도 최근에 유명해진 분야이긴 하지만 그림 그리는 AI 등등 성능이 많이 올라오면서 이쪽 분야를 공부하고자 하는 사람들이 많아진 것 같다. 흔히 듣는 인공지능에 대한 용어들 중 AI, 딥러닝, 머신러닝, 데이터 사이언스나 빅데이트 등등 혼용해서 사용되는 경우가 많다. 그러다보니 결국 deep learning이란 무엇이고, 어떤 걸 공부하는 분야인지 애매해지는 경우가 생긴다. 지금부터 작성할 글들은 스탠포드 강의인 [cs231n](https://cs231n.github.io/) 관련 블로그를 참고했으며, 사실상 거의 번역본이라고 보면 된다. 모든 저작권은 해당 홈페이지에 있으며, 본인은 이를 일종의 공부 목적/도움을 받고자 하는 불특정 다수에게 어느 정도 내가 이해한 바를 기준으로 전달하려고 작성하게 되었다.

<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/210956163-47545d18-c612-4669-a8ff-32b4dbb26dfd.png" width="700"/>
</p>

---

# What is AI?
이번에 작성하는 글은 일종의 <U>오티</U>와 같다. 본격적으로는 다음 글부터 이론적인 내용이 나오는데, 우선 강의에서 다루고자 하는 큰 주제가 무엇인지 짚고 넘어가고 싶었다. AI는 <U>artificial intelligence</U>의 약자로, 인공적으로 생성해낸 지능이라고 말할 수 있다. 본인은 무교라 종교적인 이야기를 하고자 하는 것은 아니지만, 인간이 창조할 수 있는 불가능의 영역 중 하나가 바로 인류/혹은 그와 유사한 지성을 가진 객체가 될 수 있을 것 같은데, 왜냐하면 감정이나 이성의 영역이 우주만큼 무한하고 intractable한 영역이라고 생각하기 때문이다. 그럼에도 불구하고 본인은 공대생으로 이 진로를 택했고, 공부하면서 느낀 점은 마치 천문학과에서 이런저런 우주의 비밀을 풀어내는 것처럼 인간도 어쩌면 인공지능을 해결하는 것이 미지의 영역에 발을 들이는 것이라 느끼기 시작했다. 물론 지금은 그런 걸 신경쓰기보단 SOTA 논문 찾기에 바쁘지만,,,   
아무튼 어찌저찌 다시 결론을 내자면 AI는 인간의 지성/지능을 대표하는 하나의 객체라고 말할 수 있고, 이런 객체가 <U>로봇</U>으로 나타날수도(하드웨어), <U>프로그램</U>으로 나타날수도(소프트웨어) 있다. 인간이 여러 감각 정보들을 받아들인 후 뇌에서 이를 처리해서 특정 정보로 인식하는 프로세스를 컴퓨팅 환경으로 생각하면, 특정 modality를 sensing하는 인터페이스가 있고 이를 종합적으로 처리할 수 있는 프로세싱 모듈로 하여금 정보 해석 능력을 요구하게 된다.   
따라서 우리가 흔히 가장 큰 바운더리로 언급할 수 있는 것이 AI이며, 이는 인공적으로 만든 모든 지능의 객체가 표현되는 방식이라고 볼 수 있다. 이러한 AI를 구현하는데 필요한 것이 바로 인터페이스로 하여금 받아들이는 <U>정보(information)</U>, 정보 해석 능력을 요구당하는 <U>기계의 학습(machine learning)</U>으로 구성된다. 이를 최근 들어 조금 더 세분화하여 AI 최근 분야에서는 정보 처리와 관련된 기술을 <U>data processing/data science</U>로 분류했으며, 데이터 사이언스에서 주로 포커싱하는 것은 딥러닝/머신러닝과 같이 기계가 학습되는 부분에 대한 방법론을 제시하는 것보다 정보를 잘 정제해서 유의미한 인사이트를 알고리즘에 활용하고자 하는 것이다. 그리고 머신러닝의 다양한 방법론 중 하나인 neural network(신경망) 학습이 gradient descent based optimization과 빅데이터(방대한 데이터를 의미한다), GPU와 같은 하드웨어의 발전으로 현실적인 연구가 가능해지면서 발전한 것이 딥러닝(deep learning)이고, 아마도 대부분 최근에 AI와 관련되어 들어보았던 내용은 딥러닝 base인 연구들이 많았을 것이다. 

<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/210958358-5a0abde7-49fc-47b1-a5aa-08dcd5084c8f.png" width="700"/>
</p>

크게 데이터와 머신러닝의 축으로 진행되던 AI에서 <U>딥러닝</U> 분야가 발전된 이유는 feature engineering 때문이다. 컴퓨터에게 데이터로 하여금 잘 정제해서 유의미한 인사이트를 전달하는 것이 필요한데, 왜냐하면 전통적인 머신러닝 방식은 데이터를 가지고 와서 이를 분류하거나 서로 다른 이미지에서 같은 물체를 찾아내는 작업에 등등에 대해 여러 정형화된 알고리즘을 활용했고, 만약 데이터셋의 feature를 제대로 가공하지 않으면 좋은 성능을 기대하기 힘든 경우가 많았다. 결국 인공지능인데, input에 대해 기대하는 output을 라벨링하는 것 뿐만 아니라, input으로 들어가는 modality에서 유의미한 feature를 가공하는 작업조차 인간이 하나의 알고리즘으로 만들어줘야하고, 사실상 이렇게 만들어진 알고리즘은 <U>데이터 수가 많아질수록 일반화 성능이 떨어진다</U>는 문제가 있다.   
결국 우리는 input에서 스스로 유의미한 feature를 찾아내고 이를 활용하여 결과를 낼 수 있는 시스템을 만들고 싶었고, 바로 deep learning은 deep neural network based learning을 활용하여 기존 머신러닝의 성능을 뛰어넘은 분야가 되었다.

<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/210959561-07549eed-d4d4-4fc4-a4ec-27163c86dc04.png" width="400"/>
</p>

간단하게 설명하면 다음과 같다. Input space를 $X$, feature space를 $Y$, 각 input $x \sim X$에 대해 대응되는 output $z \sim Z$가 있다고 가정해보자. 여기서 space는 하나의 <U>집합</U>이고, 물론 우리는 세상에 존재하는 모든 인과관계에 대한 supervision을 가질 수 없기 때문에 각 space는 열린계로 가정하되, 우리가 관측 가능한 subspace에 대해서만 본다고 생각해보자. Subspace란 부분 집합이라고 생각하면 된다. 일반적인 머신러닝에서는 input을 통한 output 예측 과정이 다음과 같다. 고정된 알고리즘 $F,~G$에 대해서,

\[
    F(x) = y,~G(y) = \hat{z}\ \approx z
\]

...작성중