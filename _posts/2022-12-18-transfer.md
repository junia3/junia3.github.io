---
title: 다양한 Deep learning 학습법
layout: post
description: Training strategies
post-image: https://media.tenor.com/5LBmDW-7cHAAAAAC/career-woman-multitasking.gif
category: paper review
use_math: true
tags:
- AI
- deep learning
- training method
- transfer learning
- knowledge distillation
- multitask
- contrastive learning
---

이번 게시물은 딥러닝 네트워크를 학습시킬 수 있는 다양한 학습법에 대한 내용이다. 단순히 단일 task에 대한 학습법이 아니라 다양한 환경에서 적용될 수 있는 방법론에 대해서 다루기 때문에 이번 게시글에는 다양한 내용을 담게 되었다. 그래서 우선 글을 본격적으로 시작하기 전에 어떤 내용을 다룰 것인지 간단하게 소개를 하고 시작하도록 하겠다.

1. Transfer learning : DL optimization in different tasks
2. Knowledge distillation : Increase representation generalization with soft label
3. Continual learning : Learn various representations without losing previous tasks' performances
4. Self-supervision : Learn representations with no/little supervision

---

# 딥러닝 학습이란?
<p align="center">
    <img src="learning_methods/001.gif"/>
</p>
딥러닝은 머신러닝의 여러 기법들 중 하나인 <U>Neural Network</U>를 대량의 데이터셋을 통해 보다 깊은 layer를 학습시키는 법을 gradient based로 제안하였다. 그렇기 때문에 ImageNet에서 우승했던 기본 classification 모델부터 시작해서 현재 급속한 발전을 이루었다.   
결국 하고자 하는 말은 딥러닝이 학습하기 위해서는 <U>Task가 정의</U>되어야 하며, 해당 task를 해결하고자 할 때 사용될 modality에 의한 <U>dataset이 필요</U>하며, 이러한 dataset 형태에 따라 최적화하고자 하는 <U>loss function</U>, 그리고 gradient based로 학습시킬 때 적용할 <U>optimization method</U>로 귀결된다. 

---

# 만능 인공지능을 만들 순 없을까?
<p align="center">
    <img src="learning_methods/002.png"/>
</p>
그렇다면 결국 각 task가 정의되어야하고, 그 task에 최적화된 딥러닝 모델을 만들 수는 있으나 과연 정말 인간과 같이 <U>말도 잘하고</U>, <U>사물 구분도 잘하면서</U> 어떠한 장면을 보고 <U>질문에 대한 대답도 합리적으로 잘하면서</U> 인지에 대한 실시간 대응이 가능한 네트워크를 구성할 수 있을까?   
요즘따라 "그림 그리는 AI"나 "ChatGPT"가 유명해지며 사람들의 관심이 끌리기 시작했다.
<p align="center">
    <img src="learning_methods/003.png" width="400"/>
    <img src="learning_methods/004.png" width="400"/>
</p>
정말로 AI의 성능이 무서울 정도로 성장세를 보이고 있고, 다양한 modality에 대해 적용 가능한 네트워크 구조가 많이 발전한 것은 사실이지만, 여전히 효율적으로 모든 실생활의 문제에 적용 가능한 딥러닝은 개발되지 않은 상태다. 그렇다면 <U>하나의 task에 대해 최적화된</U> 딥러닝을 <U>다른 task에 적용할 때</U>는 어떤 방법들을 사용할 수 있는지 소개해보도록 하겠다.

---

# Transfer learning(전이 학습)
cs231n에서도 소개되는 내용인 <U>전이학습</U>은(혹은 transfer learning), 현재 연구되고 있는 다양한 딥러닝 연구 전반에서 활용될 수 있는 기법이다.   
전이학습의 정의는 'previous task'에 대해 딥러닝에 학습된 지식이나 기술이 'novel task'에서도 활용될 수 있을까 혹은 적용할 수 있을까?에 대한 접근법이다.   
예를 들어 사람을 예시로 들어보자. Chess를 잘 두는 선수는 Checkers나 바둑과 같이 비슷한 게임에 더 적응을 잘할 수 있을 것이다.
<p align="center">
    <img src="learning_methods/005.png" width="400"/>
    <img src="learning_methods/006.png" width="400"/>
</p>
다른 예시로는 수학을 잘하는 사람이 인공지능 공부를 더 잘하는 것이나, 코딩을 잘하게 되는 현상 그리고 tennis를 잘치는 사람이 탁구나 배드민턴을 금방 익히는 것과 비슷하다.   
결국 길게 소개했지만 말하고자 하는 것은 <U>'어떠한 task'</U>에 대해 최적화된 네트워크에 학습된 parameter를 이용해서 '비슷하지만 살짝 다른 task'에 대해 적용할 수 있지 않을까이다.

<p align="center">
    <img src="learning_methods/007.png" width="500"/>
</p>

일반적인 imageNet에 대해 학습된 네트워크는 학습된 필터들을 통해 이미지에서 유의미한 feature를 추출할 수 있다(General images). 이 네트워크를 보다 특성화된 <U>downstream task</U>인 classification에 적용하기 위해서 기존의 feature extractor를 가지고 파라미터 수정을 하게 된다. 처음부터 학습하는 것보다, 기존의 학습된 representation이 학습에 있어 안정적인 역할을 해줄 수 있다. 마지막으로는 support vector machine(SVM)을 사용, 기존 feature extractor를 그대로 사용하되 마지막 부분에 task-specified head를 사용하여 학습하는 것을 보여준다. 이처럼 tansfer learning 혹은 fine tuning을 하는 과정은 <U>기존 task와 새롭게 접근할 task의 관계</U>에 따라서 다른 전략으로서 정의된다. 물론 dataset의 크기도 중요한 척도가 된다.   
이렇게 기존에 학습된 딥러닝 네트워크를 활용할 때 기준점이 되는 네트워크를 <U>"pre-trained model"</U>이라 부른다. 한국말로는 '사전 학습된 네트워크'라 부른다. 사전 학습된 모델에 접근하는 법을 크게 3개의 step으로 표현하면 다음과 같다.
- Select source model : 가능한 네트워크 중에서 가장 잘 적용될 수 있는 구조를 고르는 작업. 현재 [paper with code](https://paperswithcode.com/)와 같은 플랫폼에서 다양한 연구 기관(Facebook AI, Google 등등)에서 출시한 pre-trained network나 pytorch, tensorflow에서 기본으로 제공하는 pre-trained model 등등 활용할 수 있는 network pool이 넓어졌다.
- Reuse model : 위에서 고른 pre-trained network를 학습에 전반적으로 학습하는 과정이다. 일종의 <U>'from scratch'</U>사전 학습된 네트워크를 '초기화'상태로 두고 새로운 task에 적용하는 것이다. 흔히 모델의 일부분을 사용하거나 전체를 사용하는 등 모델링 기법에 따라 학습 전략은 달라진다.
- Tune model : 경우에 따라 관심이 있는 새로운 task에 대해 input-output 관계로 네트워크를 tuning하는 것이다. 흔히 classifier 부분을 SVM으로 바꾸거나 낮은 learning rate로 학습하는 방법이 이 단계에 해당된다고 보면 된다.

결국 네트워크를 새로운 task에 학습시킬 때 '학습하고자' 하는 부분이나 방법에 대한 구분이 필요하다. 이에 대해 <U>각 레이어에 대한 gradient optimization 여부</U>를 다음과 같이 구분할 수 있다.

- Re-train : 기존에 학습된 weights를 모두 버린 뒤 새로운 weight로 업데이트하는 것
- Fine-tuning : 학습된 weight를 그대로 두고, 학습 데이터를 통해 파라미터 조정을 가하는 것
- Frozen : 학습된 weight를 그대로 유지하고, 학습 과정에서도 이를 그대로 보존하는 것

일반적으로 fine-tuning은 기존에 학습될 때 사용하는 <U>learning rate</U>의 $1/10$배 혹은 $1/100$배의 크기를 적용한다. Learning rate이 곧 prediction과 ground truth 사이에 발생한 오차에 대해 얼만큼 weight update를 진행할 지에 대한 척도가 되는데, 이 값을 줄임으로써 기존에 학습된 weight를 어느 정도는 유지하고자 하는 것이다.

---

# 데이터셋의 유사도와 크기에 따른 transfer learning
<p align="center">
    <img src="learning_methods/008.png" width="800"/>
</p>
앞서 말했던 것과 같이 사전학습된 모델을 고르고, 어떤 레이어는 처음부터 다시 학습시키거나(retrain), weight를 낮은 learning rate로 살짝 조정하거나(fine-tuning) 혹은 weight를 그대로 사용할 수 있다(frozen). 이러한 전략은 사전 학습된 모델과 새로 학습할 task의 유사도(dataset similarity), 그리고 학습 시에 사용될 새 데이터셋의 규모(dataset size)에 따라 4가지로 구분될 수 있다(위의 그림 참고).

## 데이터셋의 크기는 크지만, 기존 task와의 유사도는 떨어질 경우(Quadrant 1)
이럴 경우에는 기존의 task의 representation(학습된 weight가 implicit하게 가지고 있는 mapping 능력이라고 생각하면 된다)를 그대로 사용하는 것보다는 전체 네트워크를 학습하는 것이 성능 향상에 더 도움이 될 수 있다. 이유는 네트워크 parameter 전체를 전체적으로 다 학습할 정도로 충분한 양의 데이터셋이 있다는 가정 하에 <U>overfitting이 일어나지 않을 것</U>이고, 기존 task에 대해 최적화된 weight는 <U>유사도가 낮은 새로운 task</U>에서는 적용 가능성이 낮기 때문이다.

## 데이터셋의 크기도 크고, 기존 task와의 유사성도 충분할 경우(Quadrant 2)
사실 이럴 경우가 가장 좋긴한데, 여기서 딜레마가 발생한다. 사실상 데이터셋이 충분하다는 가정만 있다면 Quadrant 1과 같이 <U>처음부터 학습하더라도 큰 문제는 없다</U>. 그러나 기존에 학습된 parameter의 representation이 새로운 task에 대해서도 좋은 supervision을 제공할 수 있다면 초반에 local optimal에 빠지거나 optimizer가 무의미한 탐색을 하지 않고도 **빠른 속도로** 수렴 가능한 parameter를 찾을 수 있을 것이다. 따라서 이런 경우에는 주로 가장 최하층(feature extraction 뒤쪽과 classifier 부분)을 fine-tuning하거나 re-training하는 형태로 학습이 진행되며, 나머지 layer에 대해서는 학습된 parameter의 도움을 받기 위해 frozen(유지)하는 방법을 선택한다.

## 데이터셋의 크기도 작고, 기존 task와의 유사성도 떨어지는 경우(Quadrant 3)
4사분면 중 여기가 가장 까다롭다. 사실 해당 문제에 대해서는 정답이라고 명확하게 정의할 수 있는 방법은 없으며, 데이터셋이 적기 때문에 새로운 task에 대해 overfitting 없이 generalization하기 곤란하다. 보통 quadrant 2에서 다룬 것처럼 일부 레이어만 학습하는데, 여기서는 frozen하는 이유가 위의 경우와는 다르다.   
Quadrant 2에서는 학습된 weight을 통해 <U>최적화 속도를 높이거나</U> <U>성능을 향상시키기 위해</U> 일부 layer만 학습하게 되지만, Quadrant 3에서는 dataset에 specific한 네트워크를 만들기 위해서 모든 레이어를 학습하게 되면 비교적 <U>적은 양의 데이터셋에 대해</U> 네트워크가 학습될 수 밖에 없기 때문에 <U>overfitting의 위험</U>이 있다.

## 데이터셋의 크기는 작지만, 기존 task와의 유사성이 높은 경우(Quadrant 4)
이럴 경우에는 quadrant 3와 마찬가지로 학습했을 때의 <U>overfitting 문제</U>를 신경써야한다. 그렇기 때문에 보통 데이터셋의 크기가 작긴 하지만 사전 학습된 네트워크의 representation mapping이 novel task에 적용할 수 있다고 판단되는 경우(<U>similar task</U>) 굳이 classifier를 제외한 부분까지 학습시키지 않는다. 일반적으로 classifier 부분은 파라미터 수가 상대적으로 적거나 학습했을 때 task-specific하게 fine-tuning이 될 수 있으므로 적은 데이터셋으로 학습하기 용이하다.

---

# Knowledge distillation
<p align="center">
    <img src="learning_methods/009.png" width="600"/>
</p>
그 다음으로 다룰 내용은 knowledge distillation이다. 기존에 학습된 네트워크를 활용하여 새로운 task에 적용하기 위한 방법으로 제시된 transfer learning과는 살짝 다르게, knowledge distillation은 단일 task에 대해 최적화되어 좋은 성능을 보이는 pre-trained model(<U>teacher network</U>)이, 보다 얕고 가벼운 light-weight network(<U>student network</U>)를 학습시키는데 보조적인 역할을 해줄 수 있다는 것이다. 지식을 전달한다는 의미의 knowledge distillation은 temperature($T$)라는 hyperparameter를 통해서 one-hot encoding에 비해 보다 합리적인 soft label을 만들어낼 수 있고(higher entropy), 이를 학습에 활용했을 때 hard label을 사용했을 때와 비교하여 '<U>가벼운 모델로 하여금 최적화 성능을 높일 수 있다</U>'는 접근법이다.
<p align="center">
    <img src="learning_methods/010.png" width="600"/>
</p>
즉 똑똑한 네트워크(Teacher network)의 output을 따라가게끔 Student network가 학습하는 과정을 의미하며, 이 학습법의 경우 굳이 convolutional neural network 구조가 아니어도 모든 형태의 deep network에서 활용될 수 있다는 범용성이 있다. 실제로 [DeiT](https://arxiv.org/abs/2012.12877)와 같은 transformer based approach에서도 사용될 수 있는 방법이다. 해당 논문에서는 inductive bias에 대한 의존성을 가진 convolutional neural network에 비해 적은 데이터로는 추론 능력이 떨어지는 transformer 모델을 학습하는 과정에서 <U>CNN의 학습된 지식을 주는</U> 형태로 knowledge distillation을 사용하였다.   
최적화에 사용되는 loss는 다음과 같다. 학습하고자 하는 데이터셋과 hard label $(X,~Y)$과 temerature $T$에 대한 prediction student network $S(\cdot, T)$ 그리고 teacher network $R(\cdot, T)$에 대해서,

\[
    \mathcal{L} = T^2 \lambda \mathcal{L_t} + (1-\lambda) \mathcal{L_s}
\]
위와 같이 나타낼 수 있고, 각각의 loss term(student loss, teacher loss는)

\[
    \mathcal{L_s} = \mathcal{L}_{CE}(Y, S(X, 1))
\]

\[
    \mathcal{L_t} = \mathcal{L}_{CE}(S(X, T),~R(X, T))    
\]

위와 같다. 여기서 temperature에 의한 prediction은 hard label을 soft label로 만들기 위한 과정으로, 다음과 같이 원래의 softmax 대신 temperature normalized softmax 값을 사용한다.
\[
    q_i = \frac{exp(z_i/T)}{\sum_j exp(z_i/T)}
\]
$z_i$가 네트워크의 prediction에 의한 logit값이 된다고 생각하면 된다.
<p align="center">
    <img src="learning_methods/011.png" width="400"/>
    <img src="learning_methods/012.png" width="400"/>
</p>
위의 그림은 본인이 실제로 knowledge distillation 과제를 진행할 때 사용했던 CIFAR-10 데이터셋에 대한 teacher prediction(첫번째 이미지), 그리고 이 logit에 temperature $T = 40$을 적용했을 때의 soft label을 보여준다. 충분히 학습된 ResNet의 경우 CIFAR-10에 대해 95%가 넘는 정확도를 보여주었고, 이에 첫번째 이미지와 같이 <U>엔트로피가 낮은 형태의 prediction</U>을 보여주었다. 학습 시에는 이를 좀 더 누그러뜨린 <U>엔트로피가 높은 형태의 prediction</U>을 사용하기 위해 위와 같이 formulation해주게 된다.

## Why knowledge distillation??
그러면 대체 왜 knowledge distillation을 사용해야하는 것이 실제 네트워크 학습에 도움이 되는 것일까? 단순히 classification이라면, 원래의 hard label에 대해 빡세게 트레이닝하는 것이 결국 성능을 높일 수 있는 방법이지 않을까 싶다.   
Soft target의 효과를 설명하기 전에 우선 딥러닝에서 <U>왜 knowledge distillation 방법</U>이 제시가 되었는지 짚고 넘어가도록 하자. 딥러닝을 사용하며 모바일이나 임베디드 환경에서도 충분히 적용 가능한 최적화 네트워크를 구축하고 싶다.
<p align="center">
    <img src="learning_methods/013.png" width="500"/>
</p>
즉, 다양한 edge device(핸드폰, 카메라, 게임기 등)에 딥러닝을 적용할 수 있기 위해서는 그만큼의 경량화 모델이 필요하고, 이는 이전에 다루었던 [MobileNet 관련 게시글](https://junia3.github.io/blog/light)을 참고해보면 더 좋다.   
아무톤 이런 방식으로 네트워크를 경량화하고자 하는 다양한 방법들이 소개가 되었으며, 단순히 성능이 좋은 무거운 네트워크를 학습하는 방법으로는 좋은 성능을 내기가 힘들다는 문제에 부딪히게 된다.
<p align="center">
    <img src="learning_methods/014.png" width="300"/>
    <img src="learning_methods/015.png" width="300"/>
</p>
위의 <U>두 개의 사진</U>을 구분하는 task를 딥러닝이 해결한다고 생각해보자. 만약 단순히 binary classification 문제라면 네트워크는 '왼쪽은 고양이', '오른쪽은 아기'라는 mapping을 학습하게 된다. 하지만 이러한 접근법은 low entropy, 즉 이미지에 대해 어떠한 연관성도 줄 수 없다는 것이다.

## Attribute based soft label?
고양이 사진에서의 특징을 나열해보면, 스핑크스가 아니라면 털이 복실복실하고, 귀엽고, 위의 사진과 같은 경우에서는 '모자'를 쓰고 있으며, 눈망울이 크고 똘망똘망하다는 것이다. 이러한 세부적인 attribute는 오른쪽 그림에서도 어느 정도 찾아볼 수 있으며, 이러한 특성을 모두 배제하고 단순히 <U>'모 아니면 도'</U>의 학습을 하는 것은 파라미터 수가 적은 network로 하여금 일반화 성능을 떨어뜨릴 수 있다는 것이다. 그렇기 때문에 teacher network의 예측을 보다 smoothing하여, 잘 학습된 네트워크에서 특정 이미지를 보고 예측했던 <U>다른 class에 대한 logit</U>을 학습에 활용하겠다는 의미가 된다. 결국 cross entropy loss는 one-hot encoding으로 학습되기 때문에 다른 class의 예측값들은 무시되는게 맞는데, <U>이걸 활용할 수 없을까?</U>에 대한 해결책이 되는 것이다. 또다른 측면에서 바라보았을 때, soft target은 network의 prior knowledge를 대변하는 값이므로(사전 학습된 네트워크의 implicit한 함수의 결과값으로 생각할 수 있다) $S(X, T) \rightarrow R(X, T)$

## Use pre-trained model
결론을 말하자면 transfer learning, knowledge distillation 모두 '<U>사전 학습된 네트워크</U>'를 사용하는 학습법이다. 두 개의 차이점은 transfer learning은 하나의 네트워크를 다른 task에 적용하는 방법에 대해서였고, knowledge distillation은 두 개의 네트워크(deep neural network and shallow network)를 사용해서 단일의 task에 대한 성능 향상 및 학습 보조에 대한 내용이다.

---

# Continual learning
<p align="center">
    <img src="learning_methods/016.png" width="500"/>
</p>
여기 잘 학습된 자율주행이 있다고 생각해보자. 그러나 자율주행을 하기 위한 학습에 사용된 데이터셋에는 '갑자기 등장하는 고라니' 라던지 '갑자기 등장하는 캥거루'와 같은 데이터셋이 없었다고 가정해보자. 즉, 차량이 조심해야 하는 anormal situation에 <U>동물이 갑자기 등장하는 상황</U>이 포함되어 있지가 않다.   
그렇다면 차량 내부 시스템의 업데이트를 통해 해당 데이터셋에 대해 추가적으로 학습해야한다. 물론, 이런 내용에 대해서 기존에 학습된 네트워크에 단순히 데이터셋만 추가하면 된다고 생각할 수 있지만, 흔히 anormal한 상황은 학습된 네트워크를 기반으로 한다고 하더라도 <U>특별한 상황이기 때문</U>에 representation에 대해 <U>만족할 만한 성능이 나온다는 보장을 할 수 없을 뿐</U>더러, 실제 학습에 사용될 수 있는 데이터셋도 분명 한정적일 것이다.   
기존에 학습된 딥러닝에 대해서 새로운 task(갑자기 등장하는 동물에 대한 차량 통제)를 처리할 수 있게 하고는 싶은데, 원래의 성능(일반적인 상황에서의 주행)을 악화시키고 싶지는 않다. 바로 이러한 접근이 '<U>continual learning</U>'의 시작이다.   
만족스러운 continual learning이 이루어지기 위해서는 다음과 같은 요구사항이 뒷받침된다.

- 네트워크는 새로운 task에 대해 좋은 성능을 보여야한다.
- 네트워크는 기존 task에 대해서 성능을 유지해야한다.
- 네트워크는 기존 task의 데이터셋을 요구하지 않는다(memory efficiency).
- 학습 및 추론 과정에서의 time complexity(FLOPs).
- 네트워크의 storage complexity(학습 가능한 representation의 범위).

## Regularization based method
Continual learning의 다양한 방법론과 그 접근법에 대해 살펴보도록 하자. 위에서 언급했던 것처럼 '사전 학습된 representation'을 사용하는 transfer learning을 remind 해보자. 만약 <U>기존에 학습된 network의 parameter를 크게 바꾸지 않고</U> 새로운 task에 적용 가능한 학습법을 사용한다면, <U>기존 task의 성능을 어느 정도 유지</U>하면서도 <U>새로운 task에 대해 최적화</U>가 가능할지도 모른다. 바로 이러한 방법을 'Regularized based method'라 부른다. 보통 복잡한 모델은 적은 learning rate를 통해 정규화하면서 기존 task 성능을 유지한다는 측면에서 이런 이름이 지어졌으며, 대표적인 방법으로는 '<U>fine tuning</U>'이 있다.

## Rehearsal based method
이러한 방법도 있다. 기존 taks의 data에 대한 sample을 buffer에 기록하고, 지금 task를 학습시키기 위한 dataset과 동시에 활용하는 것이다. 이러한 방식으로 접근하게 되면 기존 task의 supervision을 지속적으로 제공하면서도 새로운 task에 대해 최적화가 가능하다는 장점이 있다. 대표적인 방법으로는 '<U>Learning without forgetting(LWF)</U>'이 있다.

## Architecture based model
다음 방법으로는 학습 구조에 대한 의존성을 주는 부분이다. 이미 학습된 task의 성능을 그대로 유지한 채로 다른 task를 학습하고자 하면, 단순히 네트워크를 확장시키거나 auxillary head를 활용한 학습을 고려해볼 수 있다. Rehearsal based method와 거의 유사하지만 차이가 있다면 이 task의 경우에는 네트워크의 구조를 여러 task에 맞게끔 바꾸는 것이 주된 목적이기 때문에 기존 task의 dataset도 요구한다는 점이 될 수 있다. 대표적인 방법으로는 '<U>Multitask learning</U>'이 있다.

---

# Feature extraction
앞서 간단하게 continual learning의 여러 접근 방식에 대해 살펴보았다. 이러한 방법들의 가장 근간이 되는 baseline인 feature extraction은 매우 간단하다. 다만 시작하기 전에 notation을 정리하고 넘어가도록 하자.

- $\theta_s$ : Shared parameters
- $\theta_o$ : Task-specific weights for previously(old) trained tasks
- $\theta_n$ : Randomly initialized task-specific parameters for new tasks.

Feature extraction은 shared parameters(보통 ocnvolutional layers는 모두 해당된다)를 기존 task 그대로 사용하되, 새로운 head를 붙여 new task에 대해 학습하는 것을 의미한다. 즉 앞서 소개했던 <U>transfer learning</U>의 용어로 보면, feature extractor인 convolutional network($\theta_s$)는 frozen(고정)된 상태로, new task($\theta_n$)를 최적화하는 구조가 된다. 물론 head가 서로 다르기 때문에 old task에 대한 framework($\theta_s + \theta_o$)에 영향을 주지 않기 때문에 old task에 대한 성능을 그대로 유지할 수 있다는 장점이 있으며, 단점은 feature extractor가 새로운 task에 대해 최적화될 수 없기 때문에 new task에 대한 성능 향상이 한정적이라는 것이다.

<p align="center">
    <img src="learning_methods/017.png" width="700"/>
</p>

바로 뒤에서 설명하게 될 fine-tuning과 비교한 모습은 위와 같다. ResNet 구조를 살짝 수정한 네트워크에 대한 모습을 나타낸 것인데, feature extraction은 마지막 layer인 FC(fully-connect) layer만 parameter update가 가능하고, fine tuning은 convolutional layers의 뒷부분까지 parameter 조정이 되는 것을 볼 수 있다. 그럼 바로 다음 방법인 fine-tuning에 대해서 보도록 하자.

---

# Fine tuning
<p align="center">
    <img src="learning_methods/018.png" width="300"/>
</p>
미세 조정이라는 의미대로, fine tuning은 작은 learning rate을 기반으로 기존 parameter를 미세하게 최적화하는 것을 의미한다. feature extraction보다 많은 parameter에 대해 최적화가 가능하기 때문에 new task의 성능을 더 끌어올릴 수 있다는 장점이 있으나, 만약 <U>새로운 task가 기존의 task와 상이한 경우</U> 기존 task의 성능이 급격하게 낮아질 수 있다는 문제가 있다. Feature extraction에서는 parameter $\theta_s + \theta_o$ 전체가 freeze된 상태였지만, fine tuning에서는 $\theta_s(:k) + \theta_o$(여기서 $k$는 fine tuning하고자 하는 convolutional layer의 첫 인덱스를 의미한다.) 부분만 fixed된 상태고, 나머지 weight 모두 영향을 받기 때문에 문제가 될 수 있다. 물론 fine-tuning에서 fully connected layer만 하게 되는 경우에는 기존의 feature extraction과 동일한 방법으로 취급된다.

---

# Multitask learning(MTL)

... 작성중
