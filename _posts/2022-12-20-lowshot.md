---
title: Low shot learning에 대하여
layout: post
description: Few shot, Zero shot learning
use_math: true
post-image: https://media.vlipsy.com/vlips/pTepukCR/preview.jpg
category: paper review
tags:
- Meta learning
- Low shot
- Few shot
- Zero shot
- AI
- Deep learning
---

일반적으로 네트워크를 학습시킬 때, 대량의 데이터를 통해 최적의 parameter를 찾는 과정을 생각하게 된다. 그러나 만약 inference에 사용될 데이터셋에 대한 학습 데이터가 없거나 부족하다면, 네트워크는 <U>적은 데이터로도</U> 충분히 최적화될 수 있어야한다. 여기서 출발한 개념이 바로 'Low-shot learning'이며, 여기서의 'shot'은 <U>네트워크에게 제공되는 학습 데이터셋을 의미</U>한다.

# Few shot learning
현재의 딥러닝 방법들은 few examples(적은 학습 데이터셋)을 기반으로 일반화가 불가능하다. 대부분 다량의 parameter를 업데이트하는 방법으로 충분히 <U>많은 training sample을 통한 정규화</U>에 초점이 맞춰져있으며, 특히 overfitting을 방지하기 위해 다양한 data augmentation과 같은 정규화 방식이 제안되고 있다. 그렇기 때문에 데이터가 없는 상황에서 특정 task에 대해 적용 가능한 최적화된 네트워크를 만드는 것은 어쩌면 불가능할 수 있다. 일반적인 few-shot learning(FSL)에는 다음과 같은 예시가 있다.

- Character generation : 캐릭터를 생성하는 작업의 경우, 해당 캐릭터에 대한 example이 많이 존재해야하지만, 저작권 문제나 이런 저런 이슈들로 인해 충분한 샘플을 확보하지 못할 수 있다.
- Advance Robotics
- Training sample을 얻기 힘든 task : drug discovery, FSL translation, cold-start item recommendation

Machine learning에서는 computer program은 특정 <U>task</U> $T$로부터 나오는 $E$라는 <U>experience</U>를 학습하고, 학습 결과로 나오는 <U>performance measure</U> $P$에 대한 성능 향상을 이루는 것이 주 목적이다. 예를 들어 **Image classification**이라는 <U>task</U>가 있다면, 각 클래스 별로 존재하는 **대용량의 labeled image**(클래스 별로 구분된 이미지)가 곧 computer program이 경험할 수 있는 <U>experience</U> $E$가 되고, 네트워크로 하여금 예측된 각 이미지의 class에 대한 정확도(accuracy)가 측정 메트릭, <U>performance</U>가 된다. Few-shot learning에서는 바로 여기서 말하는 experience $E$가 현저히 부족한 상황에서의 문제를 이야기하며, 이를 딥러닝에서 사용하는 용어로 표현하자면 task $T$에 대한 supervision이 limited되었다고 할 수 있다.   
FSL 방법은 주로 사용할 수 있는 <U>supervision dataset</U> $E$를 활용함과 동시에, 이미 가지고 있는 <U>prior knowledge</U>와 함께 결합하여 learning이 feasible하도록 유도하는 것이다. 예를 들어 character generation이라면 supervision은 <U>각 캐릭터에 대해 존재하는 적은 샘플들</U>을 의미하고, 같이 활용될 수 있는 prior knowledge로는 캐릭터를 생성함에 있어서 <U>각 부분이나 관계에 대한 생성법</U>이 될 수 있다. 또다른 예시로 drug toxicity discovery에 대해서는 <U>새로운 분자 구조</U>가 주어지는 환경에서, 이미 알고있는 <U>유사한 형태의 분자 구조</U>를 prior knowledge로 생각해볼 수 있다. 마지막으로 image classification의 경우에는 <U>각 클래스별 라벨링된 데이터셋이 부족한 환경</U>에서, <U>다른 classification task에 대해서 학습된 네트워크</U>가 prior knowledge로 사용될 수 있다.   
또한 이러한 few-shot learning에서의 특별한 케이스로, 학습 가능한 샘플의 수가 하나만 있는 one-shot learning, 그리고 task $T$에 대해서 참고할 만한 example이 아예 없는 zero-shot learning으로 구분될 수 있다. Zero-shot learning에서는 environment $E$가 다른 modality(attribute 혹은 word embedding 등)를 가지고 있어야 하고, 이를 통해 몇몇 supervised information을 transfer하여 inference가 가능하게끔 해야한다.
<p align="center">
    <img src="lowshotlearning/001.png" width="600"/>
</p>
일반적으로 사람은 자신이 알고 있던 <U>배경 지식을 토대로 추정</U>하고(고양이를 살면서 한 번도 본적이 없는 사람이 고양이를 보고 강아지라고 한다), 만약 이렇게 추정된 내용이 잘못되었다고 하면(친구가 그건 강아지가 아니라 고양이라고 알려줌) <U>즉각적으로</U> 해당 object에 대한 지식을 얻게 되고(사실 강아지가 아니라 고양이었다는 사실을 알게됨), 다음 번에 다시 해당 object를 보게 되면(길고양이를 다시 마주함) 그때는 <U>잘못된 추론이 아닌 제대로 된 정답을 낼 수 있다</U>. 이를 딥러닝의 일련의 과정으로 나타내면 error를 통한 loss 발생이 한번에 해당 task에 대한 optimization으로 이어져서 한 번의 경험(데이터셋)으로도 일반화가 가능하다. 물론 이는 사람의 경우이고, 딥러닝에서는 단순히 이미지 하나에 대해서만 최적화를 하는 것은 optimal solution이 될 수 없다. 결국 이전에 우리가 진행했던 supervised learning에서의 학습법인 'learn from scratch' 방식을 사용할 수 없다.
<p align="center">
    <img src="lowshotlearning/002.png" width="600"/>
</p>
따라서 위와 같이 'support set'이라는 학습 가능한 하나의 에피소드를 구성하게 된다. 여기서 $N$-classes $K$-shots라 표현된 부분은, 학습에 사용될 support set의 클래스 개수가 $N$이고 각 클래스 별로 존재하는 샘플의 수가 $K$라는 것이다. 그리고 Query set은 이렇게 최적화된 네트워크를 통해 실제로 추론을 진행할 샘플이라고 보면 된다.
<p align="center">
    <img src="lowshotlearning/003.png" width="400"/>
    <img src="lowshotlearning/004.png" width="400"/>
</p>

일반적인 supervised learning은 image classification에서 첫번째 이미지와 같이, <U>모든 클래스에 대해</U> $N$개의 샘플이 있다면 그 중에서 $K$개를 training, 나머지 $N-K$개를 testing에 사용한다. 그러나 few-shot learning에서는 이와는 약간 다르게 <U>class중의 일부</U>(위의 예시에서는 5개)를 pre-training 및 training dataset에 사용하고, 나머지 class 5개에 대해서 <U>support set</U>(사전 학습된 데이터셋과 겹치지 않는 class)를 구성하게 되고, task에 맞게 적은 샘플들로만(ex. $3$ samples) 구성한다. 그리고 학습될 때 사용되지 않는 데이터(ex. $N-3$ samples)는 <U>query set</U>으로 이후 few-shot training의 성능 평가에 사용된다. Few-shot learning의 접근법에는 다음과 같은 방식들이 있다.

- Transfer learning
- Data augmentation/Transformation/Synthesis
- Meta Learning(learning to learn)
- Metric based approach(Embedding Learning)
- Multi-task Learning
- Generative learning

여기서 transfer learning, multi-task learning과 관련된 부분은 앞서 게시글 중 [다양한 딥러닝 학습법](https://junia3.github.io/blog/transfer)에서 다룬 내용과 같다. 이 중에서 이번 글에서는 '<U>학습 전략을 위한 학습</U>'인 meta learning 그리고 '<U>metric 기반 추론법</U>'인 embedding learning에 대해 살펴볼 것이다.

---

# Utilizer prior knowledge for FSL(Few-Shot Learning)
다른 게시글에서도 언급했던 내용인데, transfer learning은 각 클래스 별로 적은 샘플만 가지고는 잘 작동하지 않는다. 그리고 fine tuning을 마지막 레이어에 대해서만 진행한다고 해도 학습에 사용되는 sample 개수가 너무 부족하기 때문에 <U>overfitting</U>의 위험성이 높다. 따라서 다른 유사한 problem들로부터 experience를 획득하고, 이렇게 얻은 prior knowledge를 활용하는 방식을 채택하게 된다. 이러한 prior-knowledge를 각 domain에서 얻는 방법으로는,

1. Dataset으로부터 얻는 방법
2. Similarity로부터 얻는 방법
3. Learning으로부터 얻는 방법

크게 세 방법으로 구분될 수 있다.

## Prior knowledge about data

Dataset으로부터 prior knowledge를 얻는 방법은 비교적 심플하며, 정말 말 그대로 support set의 augmented dataset을 통해 진행된다.
<p align="center">
    <img src="lowshotlearning/005.png" width="600"/>
</p>
예를 들어 학습에 사용될 support set인 $D_{train}$이 있다고 해보자. 여기에서 추출할 수 있는 sample과 label pair에 해당되는 $(x_i,~y_i)$에 대해, 학습된 transformation function $t$를 적용해서 augmented support set $(t(x_i),~y_i)$를 ouput으로 얻을 수 있다. 이에 추가적으로 labeling이 부적합하거나 완료되지 못한 샘플 $(\bar{x},~-)$에 대해 $D_{train}$을 기반으로 라벨링을 진행한다. 즉, 예측값을 토대로 $(\bar{x},~t(\bar{x}))$와 같이 labeling을 하는 것이다. 또한 similar data sets로부터의 샘플 $(\hat{x}\_j, \hat{y}\_j)$를 aggregator $t$를 통해 조합한 output $(t( \hat{x}\_j ),~t( \hat{y}\_j))$를 도출하게 된다. 여기서는 mixup을 사용한다. 이처럼 transformer $t$가 prior knowledge로 사용되어 각 dataset category에 따른 output을 만들어낸다.

## Prior knowledge about learning
<p align="center">
    <img src="lowshotlearning/006.png" width="600"/>
</p>
Transfer learning은 사실 이 카테고리에 속하는 내용이다. 그러나 보다 좋은 방법이 바로 <U>Meta learning</U>이라는 방법이고, 학습 전략을 위한 학습법이다. 만약 task $T$를 해결하고 싶다면, meta-learning 알고리즘은 training task $T_i$의 여러 배치에 대해서 학습이 되며, 이때 중요한 것은 모든 $T_i$에 대해
\[
        T\_i \cap T = \emptyset
\]
임이 보장되어야 한다. 결국 이러한 다양한 task인 $T_i$에 대해서 학습되면서 정말 풀고자 하는 task $T$를 잘 학습하고자 하는 것이다. 쉽게 비유하자면 수능을 잘 풀기 위해서 모의고사를 많이 푸는 것이다. Training data에 대한 multiple task가 학습이 되고, 이러한 multiple task의 결과로 learning algorithm을 meta-learning한다. 이렇게 최적화된 learning algorithm을 사용해서 network를 학습시키고, 이렇게 <U>최적의 방법으로 최적화된</U> model을 사용하여 실제 task에 대한 성능을 확인한다.
<p align="center">
    <img src="lowshotlearning/007.png" width="600"/>
</p>
각 base set은 여러가지의 episode로 구성되고, 각각의 episode는 (support set, query set)으로 이루어져있다. 앞서 언급한 learning algorithm을 meta-learning하는 부분이 바로 이 base set을 사용하는 과정이다. 학습법에 대한 최적화가 끝나게 되면, 해당 방법을 통해 support set으로 네트워크를 학습한다. 이때는 실제 task에 대한 $N$-ways $K$-shots support set을 학습에 사용한 뒤 실제 task의 query set에 대한 예측 성능을 확인하게 된다. 모델은 여러 episode가 포함된 batch를 해결하면서 파라미터를 업데이트하고, 이러한 방법을 통해 새롭게 unseen few-shot classification task가 나왔을 때도 안정적이고 효과적으로 학습할 수 있는 학습법을 찾게 된다.   
   
[MAML(Model-Agnostic Meta-Learning)](https://arxiv.org/pdf/1703.03400.pdf)이 이러한 learning 알고리즘 중 하나로 소개되는데, meta learning을 활용하면서도 동시에 neural network를 <U>두 가지의 backpropagation을 진행</U>하면서 최적화한다. 가장 메인이 되는 컨셉은, neural network를 학습하는 과정에서 빠르고 적은 샘플로도 새로운 classification task에 적응 가능한 parameter를 가지게끔 학습하는 구조를 잡는 것이다.
<p align="center">
    <img src="lowshotlearning/008.png" width="400"/>
</p>
따라서 MAML은 총 두 개의 neural network 구조를 가지고, 두 네트워크는 서로 같은 구조를 공유한다. 즉 하나의 네트워크를 통해 두가지의 역할을 수행하는데, 그 중 하나는 learner(학습자)로서 앞서 언급했던 것과 같이 새로운 task에 대해 잘 학습할 수 있는 학습법(meta-learning)을 학습하고, 나머지는 adapter(적응자)로서 각 task에 빠르게 적응할 수 있는 알고리즘을 학습한다. 서로 다른 task를 해결하는 과정이기 때문에, 각자의 task에 맞는 learning rate이 사용된다. 구체적인 학습 알고리즘을 각 step 별로 나타내면 아래와 같다.

- Learner(학습자)를 랜덤하게 초기화한다.
- meta-training에 사용되는 모든 episode에 대해 아래와 같은 과정을 반복한다. 반복은 특정 epoch 수만큼 진행되거나, meta-parameter가 안정화에 접어들 때까지 진행한다.   

    - Meta-training에 사용될 episode의 batch를 샘플링한다.
    - Adapter의 parameter를 learner의 parameter로 초기화한다.
    - Inner training step이 정해진 횟수만큼 진행될 때까지, adapter를 batch의 support set에 대해서 학습시키고 loss 및 gradient based optimization을 진행한다.
    - 최적화된 adapter의 parameter를 사용하여 batch의 query set에 기반한 meta-loss를 계산한다.

- meta-gradient를 계산한다. 위에서 batch의 query set에 기반한 meta-loss를 계산하였는데, 이를 토대로 meta-parameter를 최적화하고, learner의 parameter를 update한다.

<p align="center">
    <img src="lowshotlearning/009.png" width="600"/>
</p>

각 task에 대해서 구체적인 과정을 살펴보면 다음과 같다. 먼저 meta-learning에 있어 <U>학습된 learner</U> $M$을 <U>복사한 adapter</U> $f$를 만들고, $f$의 parameter를 learner의 parameter인 $\Theta$로 초기화한다. 그런 뒤 meta-training support set으로 adapter $f$를 빠르게 fine-tuning한다. 이렇게 특정 task의 support set에 대해 최적화가 끝난 adapter $f$에 query set을 적용하고, 이 과정에서 추출된 meta-learning loss를 사용하여 $\Theta$와 함께 meta-learning parameter를 최적화한다. <U>Meta-training</U> 과정에서는 MAML은 <U>initialization parameter</U>를 학습하게 되며, 각 network(adapter)가 새로운 few-shot task에 대해 빠르게 학습 및 최적화될 수 있도록 학습된다. 그리고 <U>Inference</U>에는, meta-trained model을 사용하여 meta-test set를 예측하고, 여기서 중요한 점은 query set에 대한 **추가적인 gradient는 있지만** 직접적으로 learner의 parameter는 이를 통해 **바뀌지 않는다**. 즉 학습된 초기화 지점은 고정으로, adapter 및 meta learning 과정만 학습하는 것이다. MAML 방식은 어떠한 neural network에서도 활용될 수 있기 때문에 model agnostic하다고 할 수 있다.

## Prior knowledge of similarity

..작성중