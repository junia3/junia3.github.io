---
title: Low shot learning에 대하여
layout: post
description: Few shot, Zero shot learning
use_math: true
post-image: https://github.com/junia3/junia3.github.io/blob/main/blog/lowshotlearning/fewmoment.gif?raw=true
category: paper review
tags:
- Meta learning
- Low shot
- Few shot
- Zero shot
- AI
- Deep learning
---

일반적으로 네트워크를 학습시킬 때, 대량의 데이터를 통해 최적의 parameter를 찾는 과정을 생각하게 된다. 그러나 만약 inference에 사용될 데이터셋에 대한 학습 데이터가 없거나 부족하다면, 네트워크는 <U>적은 데이터로도</U> 충분히 최적화될 수 있어야한다. 여기서 출발한 개념이 바로 'Low-shot learning'이며, 여기서의 'shot'은 <U>네트워크에게 제공되는 학습 데이터셋을 의미</U>한다.

# Few shot learning
현재의 딥러닝 방법들은 few examples(적은 학습 데이터셋)을 기반으로 일반화가 불가능하다. 대부분 다량의 parameter를 업데이트하는 방법으로 충분히 <U>많은 training sample을 통한 정규화</U>에 초점이 맞춰져있으며, 특히 overfitting을 방지하기 위해 다양한 data augmentation과 같은 정규화 방식이 제안되고 있다. 그렇기 때문에 데이터가 없는 상황에서 특정 task에 대해 적용 가능한 최적화된 네트워크를 만드는 것은 어쩌면 불가능할 수 있다. 일반적인 few-shot learning(FSL)에는 다음과 같은 예시가 있다.

- Character generation : 캐릭터를 생성하는 작업의 경우, 해당 캐릭터에 대한 example이 많이 존재해야하지만, 저작권 문제나 이런 저런 이슈들로 인해 충분한 샘플을 확보하지 못할 수 있다.
- Advance Robotics
- Training sample을 얻기 힘든 task : drug discovery, FSL translation, cold-start item recommendation

Machine learning에서는 computer program은 특정 <U>task</U> $T$로부터 나오는 $E$라는 <U>experience</U>를 학습하고, 학습 결과로 나오는 <U>performance measure</U> $P$에 대한 성능 향상을 이루는 것이 주 목적이다. 예를 들어 **Image classification**이라는 <U>task</U>가 있다면, 각 클래스 별로 존재하는 **대용량의 labeled image**(클래스 별로 구분된 이미지)가 곧 computer program이 경험할 수 있는 <U>experience</U> $E$가 되고, 네트워크로 하여금 예측된 각 이미지의 class에 대한 정확도(accuracy)가 측정 메트릭, <U>performance</U>가 된다. Few-shot learning에서는 바로 여기서 말하는 experience $E$가 현저히 부족한 상황에서의 문제를 이야기하며, 이를 딥러닝에서 사용하는 용어로 표현하자면 task $T$에 대한 supervision이 limited되었다고 할 수 있다.   
FSL 방법은 주로 사용할 수 있는 <U>supervision dataset</U> $E$를 활용함과 동시에, 이미 가지고 있는 <U>prior knowledge</U>와 함께 결합하여 learning이 feasible하도록 유도하는 것이다. 예를 들어 character generation이라면 supervision은 <U>각 캐릭터에 대해 존재하는 적은 샘플들</U>을 의미하고, 같이 활용될 수 있는 prior knowledge로는 캐릭터를 생성함에 있어서 <U>각 부분이나 관계에 대한 생성법</U>이 될 수 있다. 또다른 예시로 drug toxicity discovery에 대해서는 <U>새로운 분자 구조</U>가 주어지는 환경에서, 이미 알고있는 <U>유사한 형태의 분자 구조</U>를 prior knowledge로 생각해볼 수 있다. 마지막으로 image classification의 경우에는 <U>각 클래스별 라벨링된 데이터셋이 부족한 환경</U>에서, <U>다른 classification task에 대해서 학습된 네트워크</U>가 prior knowledge로 사용될 수 있다.   
또한 이러한 few-shot learning에서의 특별한 케이스로, 학습 가능한 샘플의 수가 하나만 있는 one-shot learning, 그리고 task $T$에 대해서 참고할 만한 example이 아예 없는 zero-shot learning으로 구분될 수 있다. Zero-shot learning에서는 environment $E$가 다른 modality(attribute 혹은 word embedding 등)를 가지고 있어야 하고, 이를 통해 몇몇 supervised information을 transfer하여 inference가 가능하게끔 해야한다.
<p align="center">
    <img src="lowshotlearning/001.png" width="600"/>
</p>
일반적으로 사람은 자신이 알고 있던 <U>배경 지식을 토대로 추정</U>하고(고양이를 살면서 한 번도 본적이 없는 사람이 고양이를 보고 강아지라고 한다), 만약 이렇게 추정된 내용이 잘못되었다고 하면(친구가 그건 강아지가 아니라 고양이라고 알려줌) <U>즉각적으로</U> 해당 object에 대한 지식을 얻게 되고(사실 강아지가 아니라 고양이었다는 사실을 알게됨), 다음 번에 다시 해당 object를 보게 되면(길고양이를 다시 마주함) 그때는 <U>잘못된 추론이 아닌 제대로 된 정답을 낼 수 있다</U>. 이를 딥러닝의 일련의 과정으로 나타내면 error를 통한 loss 발생이 한번에 해당 task에 대한 optimization으로 이어져서 한 번의 경험(데이터셋)으로도 일반화가 가능하다. 물론 이는 사람의 경우이고, 딥러닝에서는 단순히 이미지 하나에 대해서만 최적화를 하는 것은 optimal solution이 될 수 없다. 결국 이전에 우리가 진행했던 supervised learning에서의 학습법인 'learn from scratch' 방식을 사용할 수 없다.
<p align="center">
    <img src="lowshotlearning/002.png" width="600"/>
</p>
따라서 위와 같이 'support set'이라는 학습 가능한 하나의 에피소드를 구성하게 된다. 여기서 $N$-classes $K$-shots라 표현된 부분은, 학습에 사용될 support set의 클래스 개수가 $N$이고 각 클래스 별로 존재하는 샘플의 수가 $K$라는 것이다. 그리고 Query set은 이렇게 최적화된 네트워크를 통해 실제로 추론을 진행할 샘플이라고 보면 된다.
<p align="center">
    <img src="lowshotlearning/003.png" width="600"/>
</p>

..작성중