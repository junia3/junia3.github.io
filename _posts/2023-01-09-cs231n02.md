---
title: cs231n 내용 요약 (2) - Linear classification
layout: post
description: Lecture summary
use_math: true
post-image: https://user-images.githubusercontent.com/79881119/210934049-762c2540-c097-4107-89ba-32bd2b8bc9f3.png
category: deep learning
tags:
- AI
- Deep learning
- cs231n
---

# 이전 글에서...

이전 포스팅 기준으로 컴퓨터비전에서 가장 대표적인 task인 image classification에 대해서 설명했다. 그리고 간단한 모델인 KNN(k -Nearest Neighbor) classifier에 대한 소개도 했었다. Image Classification에서 해결해야할 여러 문제들을 제시했고, 이러한 문제들을 해결하기 위해 data driven algorithm을 사용한다고 언급했었다. 그러나 단순히 각 샘플에 대한 거리 메트릭 비교를 통한 분류의 경우 다음과 같은 두 가지 문제점을 가지고 있다.


1. 이 classifier는 test data에 대한 대조군으로 모든 training data를 계속 기억해야한다. 그러므로 이 데이터가 계속 메모리를 차지하고 있기 때문에 메모리가 비효율적으로 사용된다.
2. 하나의 데이터를 분류해내기 위해 모든 training data와 비교해야하므로 계산 과정이 expensive하다.

​KNN 방식은 일반화 성능을 기대하기 힘들면서 동시에 메모리를 비효율적으로 사용한다는 점이 걸림돌이 된다. 이러한 문제로부터 앞으로 Image classification에 보다 효율적인 방법을 필요로 하였고, 그 다른 방법이 바로 Neural Network(신경망)을 이용한 학습이다. 따라서 이전까지 다뤘던 내용 전반은 사실 딥러닝에 대한 내용이 아니었고 computer vision과 같은 task를 어떠한 방식으로 정의하는지, 그리고 data-driven algorithm의 의미와 해당 방법론을 선택한 이유에 대해서였다.

---

# 신경망 회로

<U>신경망 회로 방법</U>은 인간의 신경망이 작동하는 원리를 모방한 방법이다. 

<p align="center">
    <img src = "https://user-images.githubusercontent.com/79881119/211441289-bef0f13e-b447-4d94-bcdf-3654f6264518.png"/>
</p>

뉴런이 정보를 전달하고 받아들이는 과정을 input $X$에 대해 weight $W$로 반응하고, activation function $f$(활성화 함수)를 통해 output을 내보내는 과정을 거친다. 이를 Perceptron(퍼셉트론)이라고 부르는데, 사실 퍼셉트론은 뉴런을 완전히 모방할 수 없기 때문에 dendrite, soma, axon 등등을 <U>직접 퍼셉트론의 구성 요소에 대입</U>해서 설명하는 것은 옳지 않다. 다만 정보가 전달되는 과정을 input $X$에 대한 affine transform $X\cdot W + b$으로 정의한 후, <U>논리 복잡도를 높이기 위해</U> 비선형 함수 $f$를 적용한 구조라고 생각하면 된다. 조금 더 구체적으로 들어가게 되면 우리는 어떠한 input $X$이 연산에 들어왔을 때, 사전에 정의된 parameter $W$와 $b$를 통해 output을 내보내고 여기에 비선형 함수를 적용한 결과를 하나의 점수 혹은 결과에 대한 지표로 생각해볼 수 있다.

\[
    output = f(X \cdot W + b)    
\]

만약 정의된 parameter $W$와 $b$가 입력 dataset에 대해 <U>의도대로 잘 동작하는 값</U>이라면, output과 label(ground truth)와의 차이를 구했을 때 차이가 $0$에 수렴할 것이다.

\[
    \rho(output,~label)    
\]

바로 여기서 정의해야하는 것이 output과 label의 차이를 유의미하게 계산해줄 거리 메트릭인 $\rho$이며, 이 거리 메트릭을 기준으로 신경망 회로의 파라미터를 조금씩 조정해갈 것이다. 

---

# Score function / Loss function / Cost function

위에서 언급한 거리 메트릭 $\rho$를 적절히 설정하는 것은 중요하다. Ground truth로 작용하는 label이 어떤 task에 대한 label인지도 중요하게 적용된다. 만약 거리 메트릭 $\rho$가 적절하지 않은 함수가 된다면 <U>ground truth와 output의 차이</U>를 잘 나타낼 수 없거나, 학습 과정에서 <U>수렴이 불가능한 경우</U>가 생길 수 있다. 바로 여기서 사용되는 메트릭 $\rho$를 함수 관점에서 명명한 것이 loss function 혹은 cost function이다. 둘 다 단어의 뜻을 보면 어떤 기준으로부터 <U>'얼마나 모자라는지'</U>에 대한 의미가 내포되어있고, 여기서 미리 조금 스포하자면 unsupervised learning, semi-supervised learning 그리고 supervised learning 모두 결론적으로는 ground truth 역할을 대신할 수 있는 <U>기준점</U>이 필요하다. 다시 돌아와서 하고자 했던 말은 신경망 회로 방법에서는 loss function과 cost function이 최적화에 필요하다는 것이다.   
이 글을 linear classification에 대한 글이기 때문에 해당 task에 맞춰 조금 더 설명하도록 하겠다. Loss라는 개념은 어느 정도 알았는데, 여기서 <U>score function</U>이라는 개념도 추가로 언급하겠다. Score function이란 날것의 데이터(raw data)를 classification에 맞게 각 class별 점수(score)로 mapping하는 함수가 되고, loss function이 이 score function을 이용해 예측된 score와 label과의 차이를 수치화한다. 날것의 데이터란 앞서 쭉 설명했던 것과 같이 신경망의 입력으로 사용되는 input $X$와 같은 의미다.   
그렇다면 image를 score로 mapping한다는 것이 구체적으로 어떻게 수식화가 되는지 확인해보도록 하자. $N$개의 이미지 샘플이 있고, 각각의 이미지는 $K$개의 클래스 중 하나로 대응된다.

\[
    x_i~(i = 1,~2,~3,~\cdots,~N) \rightarrow y_j~(j = 1,~2,~\cdots,~K)    
\]

각각을 행렬 차원에서 해석하게 되면 예를 들어 CIFAR-10 dataset의 input image가 $32 \times 32 \times 3$의 크기를 가지므로,

\[
    x_i \in \mathbb{R}^D,~D = 32 \times 32 \times 3 = 3072
\]

이미지 샘플 $x_i$를 하나의 차원을 가지는 벡터로 바꿀 수 있고, 이 벡터의 크기는 <U>이미지 텐서의 3개의 차원을 모두 곱한 값</U>이 된다. 예시로 사용한 CIFAR-10은 이름에서 알 수 있듯이 총 10개의 class로 구성된 dataset이므로, 앞서 언급한 식에서 $K = 10$인 경우에 해당된다.

<p align="center">
    <img src = "https://user-images.githubusercontent.com/79881119/211444992-b6f5a431-1518-4e5b-95a5-9f1bfeacc66f.png"/>
</p>

$D = 32 \times 32 \times 3$의 차원을 가지는 input image vector를 $K = 10$개의 클래스에 대한 score로 치환해야한다. 앞서 언급한 신경망 회로 방법에서는 다음과 같이 구현 가능하다.

\[
    \begin{aligned}
        W &\in \mathbb{R}^{D \times K}, \newline
        X &\in \mathbb{R}^{1 \times D}, \newline
        b &\in \mathbb{R}^{1 \times K}
    \end{aligned}    
\]

\[
    f(X \cdot W + b) = f(Y),~Y \in \mathbb{R}^{1 \times K}    
\]

Activation function $f$는 벡터의 element-wise로 연산되기 때문에 affine mapping된 $Y$의 크기 그대로 output이 결정된다. 따라서 신경망 회로에 의해 $3072$의 차원을 가지던 input 이미지가 $10$개의 클래스 score로 치환될 수 있다. 앞서 소개했던 것처럼 학습 가능한 parameter인 $W$와 $b$는 weight, bias로 부른다. 지금까지 길게 써온 내용을 4가지로 요약하면 다음과 같다.

1. 단일 matrix 곱인 $X \cdot W$는 효율적 연산이 가능하다. 여기서 효율적이란 말은 병렬화가 가능하다는 뜻으로, $X \cdot W$ 에서 각 label score가 계산되는 부분은 $W$의 each row vector이다. 따라서 class 수는 총 10개지만 연산이 병렬화가 가능하다.
​
2. $(x_i, y_i)$ 데이터는 모두 고정이다. 그러나 함수에서의 parameter인 $W$, $b$는 조정 가능하다.

3. Training data $(x, y)$를 신경망에 통과시키면서 데이터셋에 대한 output을 잘 예측하는 $W$, $b$를 찾는 것이 목표가 된다. 그렇기 때문에 이전처럼 training data를 계속 메모리에 가지고 있을 필요가 없다. 즉, 학습이 끝나고 나면 training data는 메모리에 유지될 필요가 없다.

4. KNN처럼 test image를 traing image들과 하나하나 비교해서 보는 것보다 훨씬 빠르다.

<p align="center">
    <img src = "https://user-images.githubusercontent.com/79881119/211449255-1a05c825-aaf9-438e-9ea3-a6fab2063b3c.png" width="600"/>
</p>

연산 과정을 그림으로 표현하면 위와 같이 나타낼 수 있다. 가장 우측의 결과가 classification에 사용될 예측 score가 된다. 점수표를 기준으로 해당 인공지능은 dog score가 가장 높게 나왔기 때문에 아마도 강아지라고 예측할 것이다. 물론 이건 명백한 오답.

<p align="center">
    <img src = "https://user-images.githubusercontent.com/79881119/211449542-34fdc8ae-dece-4435-a04f-5444f3982fad.png" width="600"/>
</p>

이미지가 고차원의 벡터로 확장되었는데, 3072개의 axis가 있는 좌표계에서의 하나의 점으로 해석할 수 있다. 모든 image dataset $X$를 3072차원에 그대로 mapping하고, linear classification을 진행하는 것과 같다. 위의 그림은 3072차원을 2차원으로 줄여서 이해하기 쉽게 그려놓은 그림이라고 보면 된다.   
이전에 설명했듯이 $W$의 각 row vector가 각각의 label 분류에 사용되는데, 기하적으로 해석한다면 <U>row vector를 변화시키는 것</U>은 <U>classifier가 다른 방향으로 rotate</U>하는 것과 같다. 그리고 bias에 해당하는 $b$는 classifier을 <U>원점 기준으로 이동</U>시키는 역할이라 보면 된다.   
그리고 linear classifier를 KNN 알고리즘과 같은 <U>template matching</U>으로도 해석이 가능하다. 모든 $X \cdot W$의 계산은 $W$의 row vector와 $X$(column vector)의 내적으로 해석 가능하다. 그래서 $W$는 <U>template, prototype</U>로 학습이 가능한 상태가 되어 벡터 상으로 가장 가까운 값을 찾아가게 된다. 결국 이 문제는 각 샘플을 prototype으로 사용하여 가장 가까운 $K$개의 샘플을 통해 예측을 진행하는 KNN과 동일하게 해석이 가능하다. 잘 안 와닿을 순 있지만, inner product 계산 자체가 $L_1$, $L_2$ distance를 계산한 것처럼 거리 메트릭에 해당되기 때문이다.   
이를테면 horse의 경우에도 데이터셋에 두마리의 말이 서로 마주하는 형태가 된다던지, car의 경우에 다양한 색상이나 종류의 차를 구분할 수 있어야하지만, 데이터셋 상으로 biasing된 붉은색 정보가 두드러지는 상황이 생길 수 있다. 아래 그림은 각 class에 대해 학습된 weight가 된다.

<p align="center">
    <img src = "https://user-images.githubusercontent.com/79881119/211450707-ed5bda42-180e-41f7-8184-be5f90ee3fef.png" width="1400"/>
</p>

따라서 단순히 training dataset을 통한 Linear classifier 계산을 한다면 위의 그림과 같이 각 class 별로 <U>weight prototype</U>을 만들어내고, 이 prototype에 새로운 sample을 projection 했을 때 유사할수록 그 값이 크게 나오는 메커니즘이 되기 때문에 결론적으로는 일반화 성능이 그리 좋다곤 말할 수 없는 상황이 된다. 이런 문제들을 해결하기 위해 이후에 hidden layer를 사용하여 prototype 형태의 학습에서 벗어나고자 하는 <U>심층 신경망 구조</U>를 고안하게 된다.

---

# Weight and bias

만약 bias와 weight를 따로 학습하고 연산하게 되면, 앞서 설명했던 row vector 연산의 병렬화는 bias에 대해서는 적용될 수 없다. 하지만 결국 bias가 더해지는 형태는 $X$와 $W$가 linear projection된 각각의 element에 element-wise한 합을 구하는 과정이기 때문에 굳이 따로 학습할 필요 없이 축을 추가하여 계산할 수 있다.

<p align="center">
    <img src = "https://user-images.githubusercontent.com/79881119/211451107-24831ca5-7421-4a22-a453-a01f393a9684.png" width="800"/>
</p>

Input에 $1$을 element로 추가해주고, bias를 row vector 우측으로 확장시킨다. 이렇게 되면 더이상 두 연산을 따로 처리할 필요없이 함께 최적화가 가능하다.

---

... 작성중